# ğŸš€ GuÃ­a RÃ¡pida: Push y Deploy de Feature Scraper

## ğŸ“‹ Estado Actual

âœ… **Rama creada:** `feature/scraper`  
âœ… **Commits realizados:** 2 commits con todo el cÃ³digo del scraper  
âœ… **Workflow configurado:** `.github/workflows/deploy-scraper.yml`  
â³ **Pendiente:** Push a GitHub y configurar secrets  

---

## ğŸ¯ Paso 1: Configurar Secrets en GitHub

**ANTES de hacer push**, configura los secrets:

1. Ve a: https://github.com/LaboratorioInnovacion/Next-modern-shop/settings/secrets/actions

2. Agrega estos 2 nuevos secrets:

   **DROPPERS_EMAIL**
   ```
   augustodelcampo97@gmail.com
   ```

   **DROPPERS_PASSWORD**
   ```
   Eldragon97
   ```

3. Verifica que tambiÃ©n existan (ya deberÃ­an estar):
   - POSTGRES_PASSWORD
   - NEXTAUTH_SECRET
   - SECRET
   - MERCADOPAGO_ACCESS_TOKEN

---

## ğŸš¢ Paso 2: Push de la Rama

```powershell
# Desde: e:\ecomercemil\v2\Next-modern-shop

# Ver commits realizados
git log --oneline -n 3

# Push de la rama nueva
git push -u origin feature/scraper
```

**Â¿QuÃ© pasarÃ¡?**
- âœ… Se subirÃ¡ la rama a GitHub
- âœ… Se ejecutarÃ¡ automÃ¡ticamente el workflow `deploy-scraper.yml`
- âœ… GitHub Actions construirÃ¡ la imagen con Chromium
- âœ… DesplegarÃ¡ en tu servidor self-hosted
- ğŸ§ª EjecutarÃ¡ test del scraper en modo dry-run

---

## ğŸ“Š Paso 3: Monitorear el Deploy

1. Ve a: https://github.com/LaboratorioInnovacion/Next-modern-shop/actions

2. VerÃ¡s el workflow "Deploy Scraper Branch" ejecutÃ¡ndose

3. Click en el workflow para ver los logs en tiempo real

4. Espera ~10-15 minutos (incluye construcciÃ³n de Docker)

---

## âœ… Paso 4: Verificar Despliegue

### **A) Ver logs del workflow**
En GitHub Actions verÃ¡s cada paso:
- âœ… Checkout code
- âœ… Verificar Cloudflare
- âœ… Crear .env.production
- âœ… Construir con Chromium
- âœ… Levantar servicios
- âœ… Test scraper (dry-run)

### **B) Conectarse al servidor**
```powershell
# SSH a tu servidor (ajusta segÃºn tu configuraciÃ³n)
ssh usuario@tu-servidor

# Ver contenedores
docker ps

# Ver logs del scraper
docker logs ecommerce_app --tail 50

# Ver archivos generados
docker exec ecommerce_app ls -lh scripts/logs/
docker exec ecommerce_app ls -lh scripts/data/
```

---

## ğŸ§ª Paso 5: Probar el Scraper

### **OpciÃ³n A: Desde el servidor**
```bash
# Conectarse al contenedor
docker exec -it ecommerce_app sh

# Ejecutar scraper en modo prueba
node scripts/scraper-main.js --dry-run

# Ver logs
cat scripts/logs/scraper.log
```

### **OpciÃ³n B: EjecuciÃ³n remota**
```bash
# Desde SSH
docker exec ecommerce_app npm run scrape:dry

# Scraper completo (sincroniza BD)
docker exec ecommerce_app npm run scrape
```

---

## ğŸ”„ Paso 6: Merge a Main (Opcional)

Una vez que todo funcione bien:

### **OpciÃ³n A: Pull Request**
```powershell
# Ve a GitHub y crea un PR
# https://github.com/LaboratorioInnovacion/Next-modern-shop/compare/feature/scraper
```

### **OpciÃ³n B: Merge directo**
```powershell
git checkout main
git merge feature/scraper
git push origin main
```

âš ï¸ **Al hacer merge a main:**
- Se ejecutarÃ¡ el workflow `deploy.yml` (el normal)
- NO se ejecutarÃ¡ el test del scraper automÃ¡ticamente
- TendrÃ¡s que ejecutar el scraper manualmente

---

## ğŸ›ï¸ ConfiguraciÃ³n Avanzada

### **Cambiar nÃºmero de pÃ¡ginas a scrapear**

Edita `.github/workflows/deploy-scraper.yml`:
```yaml
MAX_PAGES=2  # Cambiar a 5, 10, etc.
```

### **Desactivar test automÃ¡tico del scraper**

Comenta la secciÃ³n "Test scraper" en el workflow:
```yaml
# - name: Test scraper (dry-run)
#   continue-on-error: true
#   run: |
#     ...
```

### **Ejecutar scraper en cada deploy**

Cambia `--dry-run` por modo normal:
```yaml
docker-compose -f docker-compose.prod.yml exec -T nextjs node scripts/scraper-main.js
```

---

## âš ï¸ Troubleshooting

### **Error: Secret not found**
â†’ AsegÃºrate de haber agregado DROPPERS_EMAIL y DROPPERS_PASSWORD en GitHub

### **Error: No self-hosted runner found**
â†’ Verifica que tu runner estÃ© activo:
```bash
# En el servidor
systemctl status actions.runner.*
```

### **Build tarda mucho**
â†’ Normal, Chromium es pesado (~100MB). Primera vez puede tardar 15 min.

### **Test del scraper falla**
â†’ Revisa logs en GitHub Actions, puede ser problema de credenciales o red

---

## ğŸ“ Resumen de Archivos Nuevos

```
.github/
  â””â”€â”€ workflows/
      â””â”€â”€ deploy-scraper.yml        # Workflow para feature/scraper
  â””â”€â”€ GITHUB_SECRETS.md             # DocumentaciÃ³n de secrets

modern-shopp/
  â”œâ”€â”€ Dockerfile                    # Modificado: +Chromium
  â”œâ”€â”€ docker-compose.yml            # Modificado: +volÃºmenes +env vars
  â”œâ”€â”€ package.json                  # Modificado: +scripts scrape
  â”œâ”€â”€ SCRAPER-DOCKER.md             # GuÃ­a de uso
  â”œâ”€â”€ .env.example                  # Template de variables
  â””â”€â”€ scripts/
      â”œâ”€â”€ README.md                 # Doc del scraper
      â”œâ”€â”€ scraper-main.js           # Script principal
      â”œâ”€â”€ run-scraper.ps1           # Helper PowerShell
      â”œâ”€â”€ run-scraper.sh            # Helper Bash
      â”œâ”€â”€ config/
      â”‚   â””â”€â”€ scraper.config.js     # ConfiguraciÃ³n
      â”œâ”€â”€ scrapers/
      â”‚   â””â”€â”€ product-scraper.js    # LÃ³gica de scraping
      â”œâ”€â”€ sync/
      â”‚   â””â”€â”€ database-sync.js      # Sync con BD
      â””â”€â”€ utils/
          â””â”€â”€ helpers.js            # Utilidades
```

---

## ğŸ¯ Comando para Ejecutar Ahora

```powershell
# 1. Configurar secrets en GitHub (link arriba)

# 2. Push
cd e:\ecomercemil\v2\Next-modern-shop
git push -u origin feature/scraper

# 3. Monitorear en GitHub Actions
# https://github.com/LaboratorioInnovacion/Next-modern-shop/actions

# 4. Esperar ~15 minutos

# 5. Â¡Listo! ğŸ‰
```

---

Â¿Listo para hacer el push? ğŸš€

# Gu√≠a de Uso del Scraper en Docker

## ‚úÖ **Configuraci√≥n Completa**

El scraper ya est√° configurado para funcionar con tu despliegue Docker. Los cambios incluyen:

1. ‚úÖ Chromium instalado en el Dockerfile
2. ‚úÖ Variables de entorno en docker-compose.yml
3. ‚úÖ Vol√∫menes para persistir im√°genes y logs
4. ‚úÖ Scripts npm agregados

---

## üöÄ **C√≥mo Usar**

### **1. Reconstruir el contenedor** (solo la primera vez)
```powershell
cd modern-shopp
docker-compose down
docker-compose build
docker-compose up -d
```

### **2. Ejecutar el scraper**

#### **Opci√≥n A: Desde PowerShell (recomendado)**
```powershell
# Scraper completo (scrapea + sincroniza BD)
.\scripts\run-scraper.ps1

# Solo scraping (guarda JSON, no toca BD)
.\scripts\run-scraper.ps1 --dry-run

# Cambiar n√∫mero de p√°ginas
docker exec -e MAX_PAGES=10 -it ecommerce_app node scripts/scraper-main.js
```

#### **Opci√≥n B: Comandos directos**
```powershell
# Scraper completo
docker exec -it ecommerce_app npm run scrape

# Modo dry-run
docker exec -it ecommerce_app npm run scrape:dry

# Con m√°s p√°ginas
docker exec -e MAX_PAGES=20 -it ecommerce_app npm run scrape
```

#### **Opci√≥n C: Entrar al contenedor**
```powershell
docker exec -it ecommerce_app sh
node scripts/scraper-main.js
```

---

## üìÅ **Archivos Generados**

Los archivos se guardan en tu m√°quina local (gracias a los vol√∫menes):

- **Im√°genes**: `./public/products/` (accesibles desde tu app)
- **Logs**: `./scripts/logs/scraper.log`
- **Errores**: `./scripts/logs/errors.log`
- **JSON**: `./scripts/data/productos-sync.json`

---

## üîß **Configuraci√≥n**

Edita las variables en `docker-compose.yml`:

```yaml
environment:
  - DROPPERS_EMAIL=tu-email@gmail.com
  - DROPPERS_PASSWORD=tu-password
  - MAX_PAGES=5                    # P√°ginas a scrapear
  - HEADLESS=true                  # false para ver navegador
```

---

## üìä **Verificar Logs en Tiempo Real**

```powershell
# Ver logs del scraper
docker exec -it ecommerce_app tail -f scripts/logs/scraper.log

# Ver errores
docker exec -it ecommerce_app tail -f scripts/logs/errors.log

# Ver logs del contenedor
docker logs -f ecommerce_app
```

---

## üéØ **Ejemplo Completo**

```powershell
# 1. Levantar contenedores
docker-compose up -d

# 2. Verificar que est√©n corriendo
docker ps

# 3. Ejecutar scraper (5 p√°ginas)
.\scripts\run-scraper.ps1

# 4. Ver productos en BD
docker exec -it ecommerce_db psql -U postgres -d ecommerce -c "SELECT COUNT(*) FROM \"Product\";"

# 5. Ver logs
docker exec -it ecommerce_app cat scripts/logs/scraper.log
```

---

## ‚ö†Ô∏è **Troubleshooting**

### **Error: Chromium not found**
```powershell
# Reconstruir imagen
docker-compose build --no-cache
docker-compose up -d
```

### **Error: Permission denied en carpetas**
```powershell
# Crear carpetas si no existen
mkdir -p public/products
mkdir -p scripts/logs
mkdir -p scripts/data
```

### **Error: Cannot connect to database**
```powershell
# Verificar que postgres est√© corriendo
docker-compose ps
docker exec -it ecommerce_db pg_isready -U postgres
```

### **El scraper es muy lento**
Edita `scripts/config/scraper.config.js`:
```javascript
rateLimit: {
  requestDelay: 1000,  // 1 segundo (reducido)
  pageDelay: 3000,     // 3 segundos (reducido)
}
```

---

## üîÑ **Automatizaci√≥n (Opcional)**

Para ejecutar el scraper autom√°ticamente cada d√≠a:

### **Windows Task Scheduler**
1. Abrir "Programador de tareas"
2. Crear tarea b√°sica
3. Acci√≥n: `powershell.exe`
4. Argumentos: `-File "E:\ecomercemil\v2\Next-modern-shop\modern-shopp\scripts\run-scraper.ps1"`

### **Cron (Linux/Mac)**
```bash
# Ejecutar todos los d√≠as a las 3 AM
0 3 * * * cd /path/to/modern-shopp && ./scripts/run-scraper.sh
```

---

## üìù **Notas Importantes**

- ‚úÖ El scraper respeta rate limits (2seg entre productos, 5seg entre p√°ginas)
- ‚úÖ Las im√°genes se descargan localmente en `public/products/`
- ‚úÖ Los productos duplicados se actualizan autom√°ticamente (por SKU)
- ‚úÖ El navegador corre en modo headless dentro del contenedor
- ‚úÖ Todos los logs se guardan para auditor√≠a

---

¬øTodo listo? Ejecuta:
```powershell
docker-compose up -d
.\scripts\run-scraper.ps1
```
